{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distribution\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import visualize\n",
    "from flows import nf, nqf\n",
    "\n",
    "import os, time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# action\n",
    "parser.add_argument('--train', action='store_true', help='Train a flow.')\n",
    "parser.add_argument('--evaluate', action='store_true', help='Evaluate a flow.')\n",
    "parser.add_argument('--plot', action='store_true', help='Plot a flow and target density.')\n",
    "parser.add_argument('--restore_file', type=str, help='Path to model to restore.')\n",
    "parser.add_argument('--output_dir', default='.', help='Path to output folder.')\n",
    "parser.add_argument('--no_cuda', action='store_true', help='Do not use cuda.')\n",
    "\n",
    "# target potential\n",
    "parser.add_argument('--target_potential', choices=['u_z0', 'u_z5', 'u_z1', 'u_z2', 'u_z3', 'u_z4'], help='Which potential function to approximate.')\n",
    "\n",
    "# flow params\n",
    "parser.add_argument('--base_sigma', type=float, default=4, help='Std of the base isotropic 0-mean Gaussian distribution.')\n",
    "parser.add_argument('--learn_base', default=False, action='store_true', help='Whether to learn a mu-sigma affine transform of the base distribution.')\n",
    "parser.add_argument('--flow_length', type=int, default=2, help='Length of the flow.')\n",
    "\n",
    "# training params\n",
    "parser.add_argument('--init_sigma', type=float, default=1, help='Initialization std for the trainable flow parameters.')\n",
    "parser.add_argument('--batch_size', type=int, default=100)\n",
    "parser.add_argument('--start_step', type=int, default=0, help='Starting step (if resuming training will be overwrite from filename).')\n",
    "parser.add_argument('--n_steps', type=int, default=1000000, help='Optimization steps.')\n",
    "parser.add_argument('--lr', type=float, default=1e-5, help='Learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-3, help='Weight decay.')\n",
    "parser.add_argument('--beta', type=float, default=1, help='Multiplier for the target potential loss.')\n",
    "parser.add_argument('--seed', type=int, default=2, help='Random seed.')\n",
    "\n",
    "args = parser.parse_args(\"--train --target_potential u_z0 --flow_length 2 --n_steps 30000\".split())\n",
    "args.device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [A]. Gaussian problem (for sanity check)\n",
    "mu = 1.5 + (torch.zeros(2)).to(args.device)\n",
    "cov = torch.tensor([[1.2, 0.55],[0.55, 1.2]]).to(args.device)\n",
    "u_normal = distribution.MultivariateNormal(mu, cov)\n",
    "u_z0 = lambda z: -u_normal.log_prob(z)\n",
    "u_z0_sampler = lambda n: u_normal.sample([n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [B]. G-and-K with diff params (used to show the expressive power of NQF)\n",
    "def random_flow_param(flow):\n",
    "    GK = flow.transforms[0]\n",
    "    GK.A_.data.fill_(0)\n",
    "    GK.B_.data.fill_(2.0*torch.randn(1,1).item())  \n",
    "    GK.g_.data.fill_(-0.75 + 1.5*torch.rand(1,1).item())\n",
    "    GK.k_.data = (-1 + 2*torch.randn(GK.k_.size())-0.69315).data\n",
    "    GK.C_.data = (torch.randn(GK.C_.size())).data\n",
    "    \n",
    "n_show = 8   \n",
    "for i in range(n_show):\n",
    "    flow = nqf.NeuralQuantileFlow(dim=2, flow_length=args.flow_length, inversion=None)\n",
    "    random_flow_param(flow)\n",
    "    flow.to((args.device))\n",
    "    visualize.plot_flow_density(flow, plt.gca(), device=args.device, output_file='./example/results_ncf_{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [C]. 2D approx log-normal problem\n",
    "class ApproxLogNormal:\n",
    "    \n",
    "    def __init__(self, mus, sigmas, rho):\n",
    "        self.mus = torch.tensor(mus).view(1, 2)\n",
    "        self.sigmas = torch.tensor(sigmas).view(1, 2)\n",
    "        self.rho = torch.tensor(rho).view(1, 1)\n",
    "        self.s = 1.0\n",
    "        self.t = 0.0\n",
    "        self.k = 1.1\n",
    "        \n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        self.mus = self.mus.to(device)\n",
    "        self.sigmas = self.sigmas.to(device)\n",
    "        self.rho = self.rho.to(device)\n",
    "        mu = self.mus.view(-1).to(self.device)\n",
    "        sigma1, sigma2, rho = self.sigmas[0,0].item(), self.sigmas[0,1].item(), self.rho.item()\n",
    "        cov = torch.tensor([[sigma1**2, rho*sigma1*sigma2],[rho*sigma1*sigma2, sigma2**2]]).to(self.device)\n",
    "        self.normal = distribution.MultivariateNormal(mu, cov)\n",
    "        return self\n",
    "            \n",
    "    def log_prob(self, x):\n",
    "        n = len(x)\n",
    "        y = (x-1).sign()/2 + 0.5\n",
    "        z1, z2 = 1-(1-x).exp(), x.abs().log()        \n",
    "        dx_z = torch.zeros(x.size()).requires_grad_(True).to(x.device)\n",
    "        dx_z1, dx_z2 = 1/(1-z1), z2.exp()\n",
    "        z = (1-y)*z1 + y*z2\n",
    "        dx_z = (1-y)*dx_z1 + y*dx_z2\n",
    "        base_prob = self.normal.log_prob(z).view(n, -1)\n",
    "        log_abs_det_jacobian = torch.sum(dx_z.log(), dim=1).view(n, -1)\n",
    "        return (base_prob - log_abs_det_jacobian).view(-1)\n",
    "    \n",
    "    def sample(self, N):\n",
    "        n = N[0]\n",
    "        s, t, k = self.s, self.t, self.k\n",
    "        z = self.normal.sample([n])\n",
    "        y = z.sign()/2 + 0.5\n",
    "        z1, z2 = 1-(-z+1).log(), z.exp()\n",
    "        x = (1-y)*z1 + y*z2\n",
    "        return x\n",
    "        \n",
    "alog_normal = ApproxLogNormal(mus=[0.1, 0.1], sigmas=[0.5, 0.5], rho=0.4).to(args.device)\n",
    "u_z2 = lambda z: -alog_normal.log_prob(z)\n",
    "u_z2_sampler = lambda n: alog_normal.sample([n])\n",
    "visualize.plot_target_density(u_z2, plt.gca(), z_range=[-0.1, 3], device=args.device,output_file='./alog_normal_density_rho{:.1f}.png'.format(alog_normal.rho.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 0/30000 loss= 236.32980346679688\n",
      "A= tensor([[0.0010, 0.0010]], device='cuda:1')\n",
      "B= tensor([[0.9990, 0.9990]], device='cuda:1')\n",
      "g= tensor([[0.0010, 0.0010]], device='cuda:1')\n",
      "k= tensor([[-0.0005, -0.0005]], device='cuda:1')\n",
      "c= tensor([[0.6703, 0.6703]], device='cuda:1')\n",
      "V= tensor([[1.0000e+00, 1.0000e-03],\n",
      "        [1.0000e-03, 1.0000e+00]], device='cuda:1')\n",
      "|p(x)-q(x)|= 236.6287384033203\n",
      "\n",
      "\n",
      "finish 6000/30000 loss= 0.042456887662410736\n",
      "A= tensor([[1.0951, 1.0960]], device='cuda:1')\n",
      "B= tensor([[0.6197, 0.6225]], device='cuda:1')\n",
      "g= tensor([[0.3626, 0.3566]], device='cuda:1')\n",
      "k= tensor([[-0.1139, -0.1127]], device='cuda:1')\n",
      "c= tensor([[0.7596, 0.7652]], device='cuda:1')\n",
      "V= tensor([[1.0000, 0.3981],\n",
      "        [0.3981, 1.0000]], device='cuda:1')\n",
      "|p(x)-q(x)|= 0.20722712576389313\n",
      "\n",
      "\n",
      "finish 12000/30000 loss= 0.03231219947338104\n",
      "A= tensor([[1.1343, 1.1426]], device='cuda:1')\n",
      "B= tensor([[0.5740, 0.5805]], device='cuda:1')\n",
      "g= tensor([[0.5156, 0.5026]], device='cuda:1')\n",
      "k= tensor([[0.0487, 0.0320]], device='cuda:1')\n",
      "c= tensor([[0.7704, 0.7758]], device='cuda:1')\n",
      "V= tensor([[1.0000, 0.3928],\n",
      "        [0.3928, 1.0000]], device='cuda:1')\n",
      "|p(x)-q(x)|= 0.1092495247721672\n",
      "\n",
      "\n",
      "finish 18000/30000 loss= 0.0070716761983931065\n",
      "A= tensor([[1.1092, 1.1113]], device='cuda:1')\n",
      "B= tensor([[0.5249, 0.5220]], device='cuda:1')\n",
      "g= tensor([[0.6727, 0.6574]], device='cuda:1')\n",
      "k= tensor([[0.1437, 0.1580]], device='cuda:1')\n",
      "c= tensor([[0.7494, 0.7584]], device='cuda:1')\n",
      "V= tensor([[1.0000, 0.4018],\n",
      "        [0.4018, 1.0000]], device='cuda:1')\n",
      "|p(x)-q(x)|= 0.047420185059309006\n",
      "\n",
      "\n",
      "finish 24000/30000 loss= -0.00432469230145216\n",
      "A= tensor([[1.1110, 1.1049]], device='cuda:1')\n",
      "B= tensor([[0.5273, 0.5253]], device='cuda:1')\n",
      "g= tensor([[0.7064, 0.6817]], device='cuda:1')\n",
      "k= tensor([[0.1495, 0.1502]], device='cuda:1')\n",
      "c= tensor([[0.7246, 0.7329]], device='cuda:1')\n",
      "V= tensor([[1.0000, 0.3924],\n",
      "        [0.3924, 1.0000]], device='cuda:1')\n",
      "|p(x)-q(x)|= 0.05091610923409462\n",
      "\n",
      "\n",
      "finish 29999/30000 loss= 0.003796312492340803\n",
      "A= tensor([[1.1024, 1.1070]], device='cuda:1')\n",
      "B= tensor([[0.5294, 0.5248]], device='cuda:1')\n",
      "g= tensor([[0.7197, 0.7027]], device='cuda:1')\n",
      "k= tensor([[0.1398, 0.1416]], device='cuda:1')\n",
      "c= tensor([[0.7053, 0.7131]], device='cuda:1')\n",
      "V= tensor([[1.0000, 0.4001],\n",
      "        [0.4001, 1.0000]], device='cuda:1')\n",
      "|p(x)-q(x)|= 0.03851039335131645\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(flow, target_energy_potential, target_energy_potential_sampler, optimizer, args):\n",
    "    '''\n",
    "        minimizing KL[q(z)||p(z)] \n",
    "    '''\n",
    "    for i in range(args.start_step, args.n_steps):\n",
    "        # sample z ~ q(z)\n",
    "        n = 100 if i<args.n_steps-1 else 1000\n",
    "        z = flow.base_dist.sample((100, )).to(args.device)\n",
    "\n",
    "        # pass through flow\n",
    "        base_log_prob = flow.base_dist.log_prob(z)\n",
    "        zk, sum_log_abs_det_jacobians = flow(z)\n",
    "        q_log_prob = base_log_prob - sum_log_abs_det_jacobians\n",
    "        \n",
    "        # the target energy\n",
    "        p_log_prob = - target_energy_potential(zk)  # p = exp(-potential) ==> p_log_prob = - potential\n",
    "        \n",
    "        # compute loss and optimize\n",
    "        loss = q_log_prob - p_log_prob\n",
    "        loss = loss.mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # report\n",
    "        if i%int(args.n_steps/5) == 0 or i==args.n_steps-1: \n",
    "            print('finish {}/{}'.format(i, args.n_steps), 'loss=', loss.item())\n",
    "            flow.print()\n",
    "            print('|p(x)-q(x)|=', torch.abs(p_log_prob - q_log_prob).mean().item())\n",
    "            print('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "flow = nqf.NeuralQuantileFlow(dim=2, flow_length=1, inversion=None).to(args.device)\n",
    "file = 'exp/test/nqf_k{}.model'.format(flow.length)\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "u_z, u_z_sampler = u_z2, u_z2_sampler\n",
    "if True:\n",
    "    train(flow, u_z, u_z_sampler, optimizer, args)\n",
    "    torch.save(flow.state_dict(), file)\n",
    "else:\n",
    "    state = torch.load(file)\n",
    "    flow.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_target_density(u_z, plt.gca(), z_range=[-0.1, 3], device=args.device, output_file='./results_target_density.png')\n",
    "visualize.plot_flow_density(flow, plt.gca(), z_range=[-0.1, 3], device=args.device, output_file='./results_nqf_k{}_density.png'.format(flow.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
